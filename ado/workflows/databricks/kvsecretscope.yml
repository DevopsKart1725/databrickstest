trigger: none

parameters:
- name: databrickshost
  displayName: Databricks Host
  type: string
- name: databrickstoken
  displayName: AADToken
  type: string
- name: secretscopename
  displayName: Secret Scopename
  type: string
- name: KeyvaultresourceID
  displayName: Keyvault ResourceID
  type: string
- name: keyvaultdns
  displayName: keyvault DNS
  type: string

stages:
- stage: Build
  displayName: 'Secret_Scope'
  jobs:
  - job: Secret_Scope
    displayName: 'Secret_Scope'
    pool:
      vmImage: 'ubuntu-latest'
    steps:
    - task: UsePythonVersion@0
      displayName: 'Use Python 3.x'
      inputs:
        versionSpec: '3.x'
        addToPath: true
        architecture: 'x64'
    - task: Bash@3
      displayName: 'Install Databricks CLI'
      inputs:
        targetType: 'inline'
        script: |
          pip install -U databricks-cli
          #databricks jobs configure --version=2.1
    - task: Bash@3
      displayName: 'Configure Databricks CLI'
      inputs:
        targetType: 'inline'
        script: |
          # We need to write the pipe the conf into databricks configure --token since
          # that command only takes inputs from stdin. 
          conf=`cat << EOM
          ${{ parameters.databrickshost }}
          ${{ parameters.databrickstoken }}
          EOM`
          
          # For password auth there are three lines expected
          # hostname, username, password
          echo "$conf" | databricks configure --token
    - task: Bash@3
      displayName: 'Create Secret Scope'
      inputs:
        targetType: 'inline'
        script: 'databricks secrets create-scope --scope ${{ parameters.secretscopename }} --scope-backend-type AZURE_KEYVAULT --resource-id ${{ parameters.KeyvaultresourceID }} --dns-name ${{ parameters.keyvaultdns }} --initial-manage-principal users'